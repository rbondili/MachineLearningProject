{"cells":[{"cell_type":"markdown","source":["%md #MA707 Report - Class Demonstrations (spring 2019, DataHeroes)"],"metadata":{}},{"cell_type":"markdown","source":["## Introduction"],"metadata":{}},{"cell_type":"markdown","source":["In this notebook all the classes which will be used by the feature union and pipeline class during pre-processing of the dataset. They are fited with relevant variables from the cleaned dataset to get the transformed dataframe which will be fitted into the feature union.\n\nThe classes to be used during the pre-processing of the dataset are:\n  - `CreateTargetDF` : Assigns target variable from the merged datasets\n  - `CreateDatetimeVarsDF`: Creates new variables from the existing `datetime` variable by splitting into days, week, year, time etc.\n  - `CreateLagVarsDF`: Creates lagged versions of all the feature variables to be used in the training model to predict using the un-lagged target variable \n  - `DropNaRowsDF`: Drops all rows if there is any missing values `NaN` in the dataset\n  - `CountVectColDF`: Converts the content in a feature variable into individual tokens and counts the frequency of each tokens in each observation.\n  - `TfidfVectColDF`: Converts the content in a feature variable into individual tokens and counts frequency in each observation and multiplied with the inverse occurance frequency throughout the whole rows observations in the variable.\n  \n***Note These classes has been coded and explained in Notebook 0.2 Feature Creation***"],"metadata":{}},{"cell_type":"markdown","source":["## Contents\n1. Setup\n2. Class Demonstrations\n3. Summary"],"metadata":{}},{"cell_type":"markdown","source":["## 1. Setup"],"metadata":{}},{"cell_type":"code","source":["%run \"./0.1 Raw dataset (inc)\""],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["%run \"./0.2 Feature creation (inc)\""],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["%run \"./0.3 Feature selection (inc)\""],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["%run \"./0.4 Estimators (inc)\""],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["%run \"./0.5 Pipeline functions (inc)\""],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["## 2. Class demonstrations"],"metadata":{}},{"cell_type":"markdown","source":["The following subsections demonstrate the classes used by the `FeatureUnion` and `Pipeline` classes to create a feature-target dataframe."],"metadata":{}},{"cell_type":"markdown","source":["### 2.1 `CreateTargetDF`"],"metadata":{}},{"cell_type":"markdown","source":["This code fits the dataset `bci_dual_pdf` into the class `CreateTargetVarDF` defined in the notebook `./0.2 Feature creation (inc)` which takes the variable `bci_5tc` as its parameter and assigns it as the target variable."],"metadata":{}},{"cell_type":"code","source":["%python\nCreateTargetVarDF(var='bci_5tc') \\\n  .fit_transform(bci_dual_pdf) \\\n  .head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">49</span><span class=\"ansired\">]: </span>\n   target\n0   29966\n1   29990\n2   30337\n3   31803\n4   33276\n</div>"]}}],"execution_count":15},{"cell_type":"markdown","source":["Using the pipe operator, the dataset `bci_dual_pdf` is fitted into the defined class `CreateTargetVarDF` and then transformed to return the `bci_5tc` coulmn as the target variable using the `fit_transform` method."],"metadata":{}},{"cell_type":"markdown","source":["### 2.2 `CreateDatetimeVarsDF`"],"metadata":{}},{"cell_type":"markdown","source":["Using the class `CreateDateTimeVarsDF` defined in the notebook `./0.2 Feature creation (inc)`, the variable `date` which is a `datetime` variable is fitted into the class and then transformed into new variables of the year, month, day, dayofyear week of the year and weekday using the `.dt` method."],"metadata":{}},{"cell_type":"code","source":["bci_dual_pdf.info()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;class &apos;pandas.core.frame.DataFrame&apos;&gt;\nRangeIndex: 1597 entries, 0 to 1596\nData columns (total 32 columns):\ndate            1597 non-null datetime64[ns]\nbci             1597 non-null int64\nc5              1597 non-null float64\nc7              1597 non-null float64\np1a_03          1597 non-null int64\np2a_03          1597 non-null int64\np4_03           1597 non-null int64\np3a_iv          1597 non-null float64\nshfe_al3        1597 non-null float64\nrici            1597 non-null float64\nice_kc3         1597 non-null float64\ncme_sm3         1597 non-null float64\ncme_lc2         1597 non-null float64\nopec_orb        1597 non-null float64\nshfe_cu3        1597 non-null float64\ncme_ln1         1597 non-null float64\ncme_fc3         1597 non-null float64\np3a_03          1597 non-null int64\nshfe_rb3        1597 non-null int64\ncme_s2          1597 non-null float64\nice_sb3         1597 non-null float64\ncme_ln3         1597 non-null float64\ncme_ln2         1597 non-null float64\nice_tib3        1597 non-null float64\nice_tib4        1597 non-null float64\nbci_5tc         1597 non-null int64\ntitle_ore       1597 non-null object\ntags_ore        1597 non-null object\ncontent_ore     1597 non-null object\ntags_coal       1597 non-null object\ntitle_coal      1597 non-null object\ncontent_coal    1597 non-null object\ndtypes: datetime64[ns](1), float64(18), int64(7), object(6)\nmemory usage: 399.3+ KB\n</div>"]}}],"execution_count":19},{"cell_type":"code","source":["%python\nCreateDatetimeVarsDF(var='date',\n                     var_list=['year','month','day',\n                               'dayofyear','weekofyear','weekday']) \\\n  .fit_transform(bci_dual_pdf) \\\n  .head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">51</span><span class=\"ansired\">]: </span>\n   year  month  day  dayofyear  weekofyear  weekday\n0  2011     12    5        339          49        0\n1  2011     12    6        340          49        1\n2  2011     12    7        341          49        2\n3  2011     12    8        342          49        3\n4  2011     12    9        343          49        4\n</div>"]}}],"execution_count":20},{"cell_type":"markdown","source":["The output is the newly created 6 variables from the `datetime` variable column `date`."],"metadata":{}},{"cell_type":"markdown","source":["### 2.3 `CreateLagVarsDF`"],"metadata":{}},{"cell_type":"markdown","source":["The below section creates a lagged version of all the variables other than `bci_5tc` which is the target variable in the data set `bci_coal_pdf`. \nThe class `CreateLagVarsDF` takes two parameters `var_list` and `lag_list` which is the number of rows to be lagged and given the range `(0,2)` and then it creates a lagged version of the variables in the list `var_list`. It then returns the dataframe `bci_coal_pdf` with the lagged version of the variables concated into the existing dataframe."],"metadata":{}},{"cell_type":"code","source":["%python\nCreateLagVarsDF(var_list=['cme_ln2','rici','p1a_03','p4_03','c7',\n                          'cme_ln3','p3a_03','shfe_rb3','shfe_al3',\n                          'shfe_cu3','ice_tib3','cme_fc3','opec_orb',\n                          'ice_sb3','p3a_iv','ice_kc3','c5',\n                          'p2a_03','cme_lc2','content','cme_sm3',\n                          'ice_tib4','bci','tags','cme_ln1','cme_s2'],\n                lag_list=range(0,2)) \\\n  .fit_transform(bci_coal_pdf) \\\n  .loc[:5,['bci_lag0','bci_lag1']] \\\n  .head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">52</span><span class=\"ansired\">]: </span>\n   bci_lag0  bci_lag1\n0      3390       NaN\n1      3387    3390.0\n2      3405    3387.0\n3      3529    3405.0\n4      3697    3529.0\n</div>"]}}],"execution_count":24},{"cell_type":"markdown","source":["The output is the first 5 rows of the two lagged version of the variable `bci` with `bci_lag0` and `bci_lag1` which are lagged by zero and one respectively."],"metadata":{}},{"cell_type":"code","source":["bci_dual_pdf \\\n  .loc[:,['date','bci']] \\\n  .head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">53</span><span class=\"ansired\">]: </span>\n        date   bci\n0 2011-12-05  3390\n1 2011-12-06  3387\n2 2011-12-07  3405\n3 2011-12-08  3529\n4 2011-12-09  3697\n</div>"]}}],"execution_count":26},{"cell_type":"markdown","source":["### 2.3 `DropNaRowsDF`"],"metadata":{}},{"cell_type":"markdown","source":["Create a pipeline `xfm_pipe` with only a single object `lag` which is the class `CreateLagVarsDF` which takes all the variables in the `var_list` and concats the 3 lagged versions of all the variables back into the dataframe. \n\nFit the pipeline with the dataframe `bci_pdf` and return the transformed dataframe with the lagged variables concatenated to it."],"metadata":{}},{"cell_type":"code","source":["%python \nfrom sklearn.pipeline import Pipeline\nxfm_pipe = Pipeline(\n  steps=[('lag',CreateLagVarsDF(var_list=['cme_ln2','rici','p1a_03','p4_03','c7','cme_ln3','p3a_03','shfe_rb3','shfe_al3',\n                                          'shfe_cu3','ice_tib3','cme_fc3','opec_orb','ice_sb3','p3a_iv','ice_kc3','c5',\n                                          'p2a_03','cme_lc2','content','cme_sm3','ice_tib4','bci','tags','cme_ln1','cme_s2'],\n                                lag_list=range(0,3)))\n        ])\nxfm_pipe \\\n  .fit_transform(bci_pdf) \\\n  .loc[:,['bci_lag0',\n          'bci_lag1',\n          'bci_lag2']] \\\n  .head(3)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">54</span><span class=\"ansired\">]: </span>\n   bci_lag0  bci_lag1  bci_lag2\n0      3390       NaN       NaN\n1      3387    3390.0       NaN\n2      3405    3387.0    3390.0\n</div>"]}}],"execution_count":29},{"cell_type":"markdown","source":["The output shows the `bci` variable with its lagged versions with 0, 1 and 2 lagged and labelled as is. The entries in `bci` moves one row behind as it can be seen, the first value `3390.0` moves to the second index and third for the `bci_lag2` and it is replaced by `NaN`. These lagged predictor values will be used in training the data with the non lagged target variable."],"metadata":{}},{"cell_type":"markdown","source":["Similar to above code, a new object `row` which is the class `DropNaRowsDF` is added to the existing pipeline `xfm_pipe` The class `DropNaRowsDF` deletes all the rows with any of its entry being `NaN` or missing which is assigned by `how='any'`. \n\nFit the dataframe `bci_pdf` into the pipeline and print the first 2 rows of the lagged version of `bci`."],"metadata":{}},{"cell_type":"code","source":["%python \nfrom sklearn.pipeline import Pipeline\nxfm_pipe = Pipeline(\n  steps=[('lag',CreateLagVarsDF(var_list=['cme_ln2','rici','p1a_03','p4_03','c7','cme_ln3','p3a_03','shfe_rb3','shfe_al3',\n                                          'shfe_cu3','ice_tib3','cme_fc3','opec_orb','ice_sb3','p3a_iv','ice_kc3','c5',\n                                          'p2a_03','cme_lc2','content','cme_sm3','ice_tib4','bci','tags','cme_ln1','cme_s2'],\n                                lag_list=range(0,3))),\n         ('row',DropNaRowsDF(how='any'))\n        ])\nxfm_pipe \\\n  .fit_transform(bci_pdf) \\\n  .loc[:,['bci_lag0',\n          'bci_lag1',\n          'bci_lag2']] \\\n  .head(2)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">55</span><span class=\"ansired\">]: </span>\n   bci_lag0  bci_lag1  bci_lag2\n2      3405    3387.0    3390.0\n3      3529    3405.0    3387.0\n</div>"]}}],"execution_count":32},{"cell_type":"markdown","source":["As `xfm_pipe` is a pipeline, when we fit it, it first fits the class `CreateLagVarsDF` which then transforms and returns a dataframe with all the lagged variables concatenated to the existing. It then fits this transformed lagged dataframe into the second class `DropNaRowsDF` which then drops the rows with any missing or `NaN` values in the columns.\n\nThe output is the three lagged version of the variable `bci`."],"metadata":{}},{"cell_type":"markdown","source":["### 2.4 `CountVectColDF`"],"metadata":{}},{"cell_type":"markdown","source":["Define a class `CountVectColDF` which has a baseclass of `CountVectorizer`. It takes the parameters `col_name` which is the column name this class needs to fit into. It also takes a list of `ENGLISH_STOP_WORDS` as its parameter `stop_words` and new stop word list to be included as its parameter. The `super()` is used to call `__init__` method of the baseclass `CountVectorizer` which converts each words into a token and counts the number of tokens in each document or rows in that column.\n\nThe `fit` function fits the column name into the `super()` and then it transforms this fitted column and returns a dataframe using the `pd.Dataframe` which has new columns as feature names created from the fitted `CountVectorizer` class."],"metadata":{}},{"cell_type":"code","source":["%python \nfrom sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS\nclass CountVectColDF(CountVectorizer):\n  def __init__(self,col_name,prefix='cnt_',\n               stop_words=list(ENGLISH_STOP_WORDS),\n               add_stop_words=[]\n              ):\n    stop_words_list = stop_words+add_stop_words\n    self.col_name = col_name\n    self.prefix   = prefix\n    super().__init__(stop_words=stop_words_list)\n    return\n  \n  def fit(self,X,y=None):\n    super().fit(X[self.col_name])\n    return self\n  \n  def transform(self,X,y=None):\n    return pd.DataFrame(data=super().transform(X[self.col_name]).toarray(),\n                        columns=[self.prefix+feature_name for feature_name in super().get_feature_names()]\n                       )"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":36},{"cell_type":"markdown","source":["In this code, use the `tag` column from the fitted dataframe `bci_dual_pdf` as the parameter `col_name` into the above defined class `CountVectColDF`. The word `2012` is added to the `stop_words_list` which will be added to the list of `ENGLISH_STOP_WORDS`. The dataframe `bci_coal_pdf` is fitted and transformed to create new features or variables with the prefix `cnt_` and it then prints out the column names in the dataframe."],"metadata":{}},{"cell_type":"code","source":["%python\nCountVectColDF(col_name='tags_coal',\n               prefix='cnt_',\n               add_stop_words=['2012']) \\\n  .fit(bci_dual_pdf) \\\n  .transform(bci_dual_pdf) \\\n  .head() \\\n  .columns"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">57</span><span class=\"ansired\">]: </span>\nIndex([&apos;cnt_acquisitions&apos;, &apos;cnt_adani&apos;, &apos;cnt_adaro&apos;, &apos;cnt_administration&apos;,\n       &apos;cnt_aes&apos;, &apos;cnt_afghanistan&apos;, &apos;cnt_africa&apos;, &apos;cnt_ag&apos;, &apos;cnt_agency&apos;,\n       &apos;cnt_agnico&apos;,\n       ...\n       &apos;cnt_xstrata&apos;, &apos;cnt_yancoal&apos;, &apos;cnt_yanzhou&apos;, &apos;cnt_yukon&apos;, &apos;cnt_zambia&apos;,\n       &apos;cnt_zealand&apos;, &apos;cnt_zijin&apos;, &apos;cnt_zimbabwe&apos;, &apos;cnt_zimplats&apos;, &apos;cnt_zinc&apos;],\n      dtype=&apos;object&apos;, length=606)\n</div>"]}}],"execution_count":38},{"cell_type":"markdown","source":["The output is the list of all the feature names or tokens created from the `CountVectorizer` baseclass with the prefix `cnt`"],"metadata":{}},{"cell_type":"markdown","source":["### 2.5 `TfidfVectColDF`"],"metadata":{}},{"cell_type":"markdown","source":["Similar to `CountVectColDF`, the `TfidfVectColDF` has the baseclass `TfidfVectorizer` which counts the number of tokens in each document multiplied by the weight representing how common a word is across documents or different texts in the column."],"metadata":{}},{"cell_type":"code","source":["%python \nfrom sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\nclass TfidfVectColDF(TfidfVectorizer):\n  def __init__(self,col_name,prefix='tfidf_',\n               stop_words=list(ENGLISH_STOP_WORDS),\n               add_stop_words=[]\n              ):\n    stop_words_list = stop_words+add_stop_words\n    self.col_name = col_name\n    self.prefix   = prefix\n    super().__init__(stop_words=stop_words_list)\n    return\n  \n  def fit(self,X,y=None):\n    super().fit(X[self.col_name])\n    return self\n  \n  def transform(self,X,y=None):\n    return pd.DataFrame(data=super().transform(X[self.col_name]).toarray(),\n                        columns=[self.prefix+feature_name for feature_name in super().get_feature_names()]\n                       )"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":42},{"cell_type":"markdown","source":["Fit the dataframe `bci_dual_pdf` into the class `TfidfVectColDF` with the column name `tags` as the column to be fitted and transformed. It then returns the dataframe with all the feature names created by the `TfidfVectorizer` baseclass with the `Tf-idf` values and prints the first 5 rows of the new dataframe."],"metadata":{}},{"cell_type":"code","source":["%python\nTfidfVectColDF(col_name='tags_coal',\n               prefix='tfidf_',\n               add_stop_words=['2012']) \\\n  .fit(bci_dual_pdf) \\\n  .transform(bci_dual_pdf) \\\n  .head() "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">59</span><span class=\"ansired\">]: </span>\n   tfidf_acquisitions  tfidf_adani  ...  tfidf_zimplats  tfidf_zinc\n0                 0.0          0.0  ...             0.0    0.192856\n1                 0.0          0.0  ...             0.0    0.000000\n2                 0.0          0.0  ...             0.0    0.000000\n3                 0.0          0.0  ...             0.0    0.000000\n4                 0.0          0.0  ...             0.0    0.000000\n\n[5 rows x 606 columns]\n</div>"]}}],"execution_count":44},{"cell_type":"markdown","source":["## Summary"],"metadata":{}},{"cell_type":"markdown","source":["All the above defined class will be used in creating feature union and pipeline creation while working with the three mining datasets and performing the gridsearch on various models to predict the target variable."],"metadata":{}}],"metadata":{"name":"1. Class demonstrations","notebookId":4127496387311329},"nbformat":4,"nbformat_minor":0}
